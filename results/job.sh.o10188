Single Sentence Casei CNN 2
200, 20, relu
keep everything but operations static
loading data...
/home/s1045064/dissertation/repo-diss/sentence-classification/data/snli-GloVe-Split.p
data loaded!
model architecture: CNN-non-static
using: word2vec vectors
[('image shape', 89, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 3]), ('dropout', [0.2]), ('batch_size', 200), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 9), ('shuffle_batch', True), ('mode', 'sub'), ('alpha', 0.4), ('beta', 0.6), ('activations', [<function Iden at 0x91b4140>])]
define model architecture
define parameters of the model and update functions using adadelta
shuffle dataset and assign to mini batches. if dataset size is not a multiple of mini batches, replicate
divide train set into train/val sets
compile theano functions to get train/val/test errors
... training
epoch: 1, training time: 470.32 secs, train perf: 74.00 %, val perf: 72.55 %
epoch: 2, training time: 473.13 secs, train perf: 79.48 %, val perf: 76.88 %
epoch: 3, training time: 473.34 secs, train perf: 82.24 %, val perf: 78.70 %
epoch: 4, training time: 472.92 secs, train perf: 83.68 %, val perf: 79.25 %
epoch: 5, training time: 473.20 secs, train perf: 85.44 %, val perf: 79.50 %
epoch: 6, training time: 472.59 secs, train perf: 87.32 %, val perf: 80.19 %
epoch: 7, training time: 472.32 secs, train perf: 88.35 %, val perf: 79.80 %
epoch: 8, training time: 472.22 secs, train perf: 89.49 %, val perf: 79.78 %
epoch: 9, training time: 471.90 secs, train perf: 90.13 %, val perf: 80.09 %
epoch: 10, training time: 473.57 secs, train perf: 91.02 %, val perf: 79.30 %
epoch: 11, training time: 472.93 secs, train perf: 92.05 %, val perf: 79.40 %
epoch: 12, training time: 474.09 secs, train perf: 93.14 %, val perf: 79.49 %
epoch: 13, training time: 472.19 secs, train perf: 93.69 %, val perf: 79.18 %
epoch: 14, training time: 472.37 secs, train perf: 94.17 %, val perf: 78.59 %
epoch: 15, training time: 473.58 secs, train perf: 94.34 %, val perf: 78.47 %
epoch: 16, training time: 472.14 secs, train perf: 93.71 %, val perf: 78.40 %
epoch: 17, training time: 472.24 secs, train perf: 95.38 %, val perf: 79.17 %
epoch: 18, training time: 471.85 secs, train perf: 95.81 %, val perf: 78.59 %
epoch: 19, training time: 472.09 secs, train perf: 96.23 %, val perf: 78.23 %
epoch: 20, training time: 472.08 secs, train perf: 96.61 %, val perf: 78.20 %
epoch: 21, training time: 472.25 secs, train perf: 96.72 %, val perf: 77.59 %
epoch: 22, training time: 472.27 secs, train perf: 96.93 %, val perf: 77.94 %
epoch: 23, training time: 472.40 secs, train perf: 97.16 %, val perf: 78.20 %
epoch: 24, training time: 472.34 secs, train perf: 97.51 %, val perf: 78.68 %
epoch: 25, training time: 470.83 secs, train perf: 97.58 %, val perf: 78.18 %
0.7877
